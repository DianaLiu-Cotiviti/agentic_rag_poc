"""
Retrieval Router Agent Prompts - Retrieval Execution Planning
This module contains prompt templates for the Retrieval Router Agent, which decides
retrieval parameters, tool selection, and execution strategy based on query analysis.

Version: 2.0
Last Updated: 2026-02-02
"""


def build_retrieval_router_prompt(
    question: str,
    question_type: str,
    retrieval_strategies: list[str],
    query_candidates: list[dict],
    retrieval_hints: list[str]
) -> str:
    """
    Build retrieval router prompt for execution planning
    
    Args:
        question: Original user query
        question_type: Question type from Orchestrator
        retrieval_strategies: Strategy list from Orchestrator (e.g., ["range_routing", "bm25", "semantic"])
        query_candidates: Query candidates from Query Planner
        retrieval_hints: Retrieval hints from Query Planner
        
    Returns:
        str: Complete prompt for LLM
    """
    strategies_str = ", ".join(retrieval_strategies)
    hints_str = "\n".join(f"  - {hint}" for hint in retrieval_hints[:5])
    
    candidates_str = "\n".join(
        f"  {i+1}. [{qc['query_type']}] (weight: {qc['weight']}) \"{qc['query']}\""
        for i, qc in enumerate(query_candidates)
    )
    
    return f"""You are a Retrieval Execution Planner for a medical coding RAG system.

Your mission is to create a DETAILED RETRIEVAL EXECUTION PLAN based on:
1. High-level strategies from Orchestrator
2. Query candidates from Query Planner
3. Retrieval hints and constraints

## Input Information

**Original Question**: {question}
**Question Type**: {question_type}
**Retrieval Strategies**: {strategies_str}

**Query Candidates ({len(query_candidates)}):**
{candidates_str}

**Retrieval Hints:**
{hints_str}

## Your Task: Create Retrieval Execution Plan

### üìã STEP 1: Pre-Retrieval Filtering Decision

Decide whether to apply **pre-retrieval filtering** (e.g., range routing) to narrow the search space.

**When to Use Pre-Filtering:**
- Query contains specific CPT codes ‚Üí Use range_routing
- Query targets specific section ‚Üí Use range_routing
- Large corpus and narrow query scope ‚Üí Use range_routing

**Pre-Filtering Parameters:**
- **apply_range_routing**: true/false
- **range_filter_cpt_codes**: List of CPT codes to filter by (e.g., ["14301", "27700"])
- **range_filter_limit**: Max chunks to retrieve from range (default: 300)

**Decision Logic:**
- If "range_routing" in retrieval_strategies AND query has CPT codes ‚Üí apply_range_routing = true
- Extract CPT codes from query candidates for filtering
- Set limit based on query complexity (simple: 200, medium: 300, complex: 500)

### üéØ STEP 2: Query-Strategy Mapping

Map each query candidate to specific retrieval strategies. Not all candidates need all strategies!

**Mapping Guidelines:**

**original query**:
- Best for: All strategies (bm25, semantic, hybrid)
- Reason: Direct user intent

**expanded query**:
- Best for: semantic, hybrid
- Reason: Rich terminology benefits semantic matching
- Avoid: Pure bm25 (too long for exact matching)

**synonym query**:
- Best for: semantic, hybrid
- Reason: Captures alternative phrasings
- Avoid: Pure bm25 (different keywords may not match)

**section_specific query**:
- Best for: bm25, hybrid
- Reason: Targets specific sections/tables with exact terms
- Good for: Metadata matching

**constraint_focused query**:
- Best for: semantic, hybrid
- Reason: Conceptual constraints need semantic understanding

**Output Format:**
For each query candidate, specify which strategies to use:
```
query_strategy_mapping: [
  {{
    "query_index": 0,  # Index in query_candidates
    "strategies": ["bm25", "semantic"],  # Which strategies for this query
    "reasoning": "Original query benefits from both exact and semantic matching"
  }},
  ...
]
```

### ‚öôÔ∏è STEP 3: Retrieval Parameters Configuration

Set specific parameters for each retrieval strategy.

**BM25 Parameters:**
- **top_k**: Number of results per query (default: 15-20)
  * Simple questions: 10-15
  * Medium questions: 15-20
  * Complex questions: 20-30
- **boost_exact_match**: Whether to boost exact code/modifier matches (true/false)

**Semantic Search Parameters:**
- **top_k**: Number of results per query (default: 15-20)
  * Simple questions: 10-15
  * Medium questions: 15-20
  * Complex questions: 20-30
- **similarity_threshold**: Minimum similarity score (0.0-1.0, default: 0.0)
  * Strict retrieval: 0.3
  * Balanced: 0.0
  * Exploratory: 0.0

**Hybrid Search Parameters:**
- **top_k**: Number of results per query (default: 20)
- **bm25_weight**: Weight for BM25 scores (0.0-1.0, default: 0.5)
  * Prefer exact matching: 0.6-0.7
  * Balanced: 0.5
  * Prefer semantic: 0.3-0.4
- **semantic_weight**: Weight for semantic scores (0.0-1.0, default: 0.5)
  * Must sum to 1.0 with bm25_weight

### üîÄ STEP 4: Result Fusion Strategy

Decide how to combine results from multiple queries and strategies.

**Fusion Methods:**

**RRF (Reciprocal Rank Fusion)** - Default, recommended
- Best for: Most use cases
- How: Combines rankings from different sources
- Parameter: rrf_k (default: 60, higher = less aggressive fusion)

**Weighted Sum**
- Best for: When some queries are much more important
- How: Sum scores weighted by query candidate weights
- Uses query_candidate.weight directly

**Cascade**
- Best for: When one strategy is clearly primary
- How: Start with Strategy A, augment with Strategy B if insufficient
- Example: Start with range_routing, add semantic if < 10 results

**Parallel with Deduplication**
- Best for: Maximum coverage
- How: Run all strategies, deduplicate by chunk_id, keep highest score

**Recommended Fusion:**
- Simple questions: RRF (all queries equal weight)
- Medium questions: Weighted RRF (use query candidate weights)
- Complex questions: Parallel with deduplication + RRF

**Output:**
```
fusion_strategy: "weighted_rrf"
fusion_parameters: {{
  "rrf_k": 60,
  "use_query_weights": true,
  "boost_range_results": 1.5  # Boost chunks from range routing
}}
```

### üìä STEP 5: Execution Order & Parallelization

Define the execution order and which operations can run in parallel.

**Execution Patterns:**

**Sequential (Conservative)**
```
1. Range routing (pre-filter)
2. BM25 on filtered chunks
3. Semantic on filtered chunks
4. Fuse results
```
- Pros: Each step uses filtered space, efficient
- Cons: Slower total time
- Best for: Debugging, clear attribution

**Parallel (Aggressive)**
```
1. Range routing (pre-filter)
2. Parallel:
   - BM25 on all query candidates
   - Semantic on all query candidates
3. Fuse all results
```
- Pros: Fastest total time, maximum coverage
- Cons: More token usage if retrying
- Best for: Production, complex queries

**Hybrid (Recommended)**
```
1. Range routing (pre-filter)
2. For each query candidate in parallel:
   - Run assigned strategies (from Step 2)
3. Fuse results with RRF
```
- Pros: Balanced speed and efficiency
- Cons: Requires good query-strategy mapping
- Best for: Most use cases

**Output:**
```
execution_plan: {{
  "mode": "parallel",  # sequential | parallel | hybrid
  "steps": [
    {{"stage": "pre_filter", "action": "range_routing", "parallel": false}},
    {{"stage": "retrieval", "action": "multi_query_search", "parallel": true}},
    {{"stage": "fusion", "action": "rrf_fusion", "parallel": false}}
  ]
}}
```

### üí≠ STEP 6: Reasoning

Provide a concise 2-3 sentence explanation covering:
1. Why you chose this pre-filtering strategy
2. How you mapped queries to retrieval strategies
3. Why this fusion strategy is optimal for this query

## Decision Examples

**Example 1: Simple Definition Query**
Question: "What is CPT 14301?"
Strategies: ["range_routing", "semantic"]
Query Candidates: [original, expanded, synonym]

‚Üí pre_filtering: {{
  "apply_range_routing": true,
  "range_filter_cpt_codes": ["14301"],
  "range_filter_limit": 200
}}
‚Üí query_strategy_mapping: [
  {{"query_index": 0, "strategies": ["semantic"], "reasoning": "Original question for direct semantic match"}},
  {{"query_index": 1, "strategies": ["semantic"], "reasoning": "Expanded query with full terminology for semantic"}},
  {{"query_index": 2, "strategies": ["semantic"], "reasoning": "Synonym variant for alternative phrasings"}}
]
‚Üí retrieval_parameters: {{
  "semantic": {{"top_k": 15, "similarity_threshold": 0.0}}
}}
‚Üí fusion_strategy: "rrf"
‚Üí fusion_parameters: {{"rrf_k": 60, "use_query_weights": true, "boost_range_results": 1.3}}
‚Üí execution_plan: {{
  "mode": "hybrid",
  "steps": [
    {{"stage": "pre_filter", "action": "range_routing"}},
    {{"stage": "retrieval", "action": "semantic_search_parallel"}},
    {{"stage": "fusion", "action": "rrf_fusion"}}
  ]
}}
‚Üí reasoning: "Simple definitional query with specific CPT code requires range routing to CPT 14000 section as pre-filter. All three query candidates use semantic search only (no exact matching needed). RRF fusion with slight boost for range-routed chunks ensures section-relevant results are prioritized."

**Example 2: Modifier Compatibility Question**
Question: "Is modifier 59 allowed with CPT 14301?"
Strategies: ["range_routing", "bm25", "semantic"]
Query Candidates: [original, expanded, section_specific, synonym]

‚Üí pre_filtering: {{
  "apply_range_routing": true,
  "range_filter_cpt_codes": ["14301"],
  "range_filter_limit": 300
}}
‚Üí query_strategy_mapping: [
  {{"query_index": 0, "strategies": ["bm25", "semantic"], "reasoning": "Original query needs both exact and semantic matching"}},
  {{"query_index": 1, "strategies": ["semantic"], "reasoning": "Expanded query with full NCCI context for semantic understanding"}},
  {{"query_index": 2, "strategies": ["bm25"], "reasoning": "Section-specific query targets modifier tables with exact terms"}},
  {{"query_index": 3, "strategies": ["semantic"], "reasoning": "Synonym variant for conceptual matching"}}
]
‚Üí retrieval_parameters: {{
  "bm25": {{"top_k": 20, "boost_exact_match": true}},
  "semantic": {{"top_k": 20, "similarity_threshold": 0.0}}
}}
‚Üí fusion_strategy: "weighted_rrf"
‚Üí fusion_parameters: {{"rrf_k": 60, "use_query_weights": true, "boost_range_results": 1.5}}
‚Üí execution_plan: {{
  "mode": "parallel",
  "steps": [
    {{"stage": "pre_filter", "action": "range_routing"}},
    {{"stage": "retrieval", "action": "multi_strategy_parallel"}},
    {{"stage": "fusion", "action": "weighted_rrf_fusion"}}
  ]
}}
‚Üí reasoning: "Modifier compatibility requires both exact matches (for 'modifier 59', 'CPT 14301' terms) and semantic understanding (for policy context). Range routing pre-filters to CPT 14000 section. Original query uses both BM25+semantic, section_specific targets tables with BM25, others use semantic. Parallel execution with weighted RRF balances exact and conceptual matches."

**Example 3: Complex Policy Question**
Question: "Under what circumstances can CPT 14301 be billed separately when performed with complex repair on the same anatomical region, and what modifiers should be used?"
Strategies: ["range_routing", "hybrid"]
Query Candidates: [original, expanded, constraint_focused, section_specific, synonym]

‚Üí pre_filtering: {{
  "apply_range_routing": true,
  "range_filter_cpt_codes": ["14301"],
  "range_filter_limit": 500
}}
‚Üí query_strategy_mapping: [
  {{"query_index": 0, "strategies": ["hybrid"], "reasoning": "Original complex query needs balanced exact+semantic"}},
  {{"query_index": 1, "strategies": ["hybrid"], "reasoning": "Expanded with full terminology for comprehensive matching"}},
  {{"query_index": 2, "strategies": ["hybrid"], "reasoning": "Constraint-focused on bundling rules needs both exact and conceptual"}},
  {{"query_index": 3, "strategies": ["hybrid"], "reasoning": "Section-specific for modifier guidance"}},
  {{"query_index": 4, "strategies": ["semantic"], "reasoning": "Synonym variant for alternative policy phrasings"}}
]
‚Üí retrieval_parameters: {{
  "hybrid": {{
    "top_k": 25,
    "bm25_weight": 0.5,
    "semantic_weight": 0.5
  }},
  "semantic": {{"top_k": 20, "similarity_threshold": 0.0}}
}}
‚Üí fusion_strategy: "parallel_with_dedup"
‚Üí fusion_parameters: {{"rrf_k": 60, "use_query_weights": true, "boost_range_results": 1.4}}
‚Üí execution_plan: {{
  "mode": "parallel",
  "steps": [
    {{"stage": "pre_filter", "action": "range_routing"}},
    {{"stage": "retrieval", "action": "multi_query_hybrid_parallel"}},
    {{"stage": "fusion", "action": "rrf_dedup_fusion"}}
  ]
}}
‚Üí reasoning: "Complex multi-part question with 5 query candidates requires comprehensive retrieval. Range routing pre-filters to larger set (500) for complex question. Most queries use hybrid strategy for balanced exact+semantic matching, maximizing coverage of both specific terms and conceptual policy context. Parallel execution with deduplication ensures diverse results from all angles."

**Example 4: PTP Question (Two CPT Codes)**
Question: "Can CPT 14301 and 27700 be billed together?"
Strategies: ["range_routing", "bm25", "semantic"]
Query Candidates: [original, expanded, section_specific, synonym]

‚Üí pre_filtering: {{
  "apply_range_routing": true,
  "range_filter_cpt_codes": ["14301", "27700"],
  "range_filter_limit": 400
}}
‚Üí query_strategy_mapping: [
  {{"query_index": 0, "strategies": ["bm25", "semantic"], "reasoning": "Original PTP question for both exact and semantic"}},
  {{"query_index": 1, "strategies": ["semantic"], "reasoning": "Expanded with both code descriptions for semantic"}},
  {{"query_index": 2, "strategies": ["bm25"], "reasoning": "Section-specific targets PTP tables with exact terms"}},
  {{"query_index": 3, "strategies": ["semantic"], "reasoning": "Synonym for conceptual billing compatibility"}}
]
‚Üí retrieval_parameters: {{
  "bm25": {{"top_k": 20, "boost_exact_match": true}},
  "semantic": {{"top_k": 20, "similarity_threshold": 0.0}}
}}
‚Üí fusion_strategy: "weighted_rrf"
‚Üí fusion_parameters: {{"rrf_k": 60, "use_query_weights": true, "boost_range_results": 1.6}}
‚Üí execution_plan: {{
  "mode": "parallel",
  "steps": [
    {{"stage": "pre_filter", "action": "range_routing_multi_code"}},
    {{"stage": "retrieval", "action": "multi_strategy_parallel"}},
    {{"stage": "fusion", "action": "weighted_rrf_fusion"}}
  ]
}}
‚Üí reasoning: "PTP question with two CPT codes requires range routing to both code sections (14xxx and 27xxx). Section-specific query uses BM25 to find exact PTP table entries, while other queries use semantic to understand billing context. Higher boost (1.6) for range results ensures code-specific rules are prioritized over general guidelines."

## Now Create Retrieval Execution Plan

Based on the input information above, provide your retrieval execution plan using the RetrievalRouterDecision schema.
"""


def build_tool_calling_prompt(
    question: str,
    question_type: str,
    retrieval_strategies: list[str],
    query_candidates: list[dict],
    question_keywords: list[str]
) -> str:
    """
    Build prompt for LLM-driven tool calling mode
    
    This prompt guides the LLM to call retrieval tools directly using OpenAI function calling.
    
    Args:
        question: Original user query
        question_type: Question type from Orchestrator
        retrieval_strategies: Strategy list from Orchestrator
        query_candidates: Query candidates from Query Planner
        question_keywords: Extracted keywords from Orchestrator
        
    Returns:
        str: Complete prompt for LLM
    """
    strategies_str = ", ".join(retrieval_strategies)
    keywords_str = ", ".join(question_keywords[:10])
    
    candidates_str = "\n".join(
        f"  {i+1}. [{qc['query_type']}] (weight: {qc['weight']}) \"{qc['query']}\""
        for i, qc in enumerate(query_candidates)
    )
    
    return f"""You are an intelligent Retrieval Agent for a medical coding RAG system.

Your mission is to **USE THE AVAILABLE TOOLS** to retrieve relevant information based on the user's question.

## Input Information

**Original Question**: {question}
**Question Type**: {question_type}
**Recommended Strategies**: {strategies_str}
**Keywords**: {keywords_str}

**Query Candidates ({len(query_candidates)}):**
{candidates_str}

## Available Tools

You have access to the following retrieval tools:

1. **range_routing(cpt_code, limit)**: Pre-filter chunks by CPT code range
   - Use when: Question contains specific CPT codes
   - Parameters: cpt_code (int), limit (int, default: 300)
   - Returns: Set of chunk IDs in that CPT range

2. **bm25_search(query, top_k, boost_exact_match)**: Keyword-based search
   - Use when: Need exact term matching
   - Parameters: query (str), top_k (int, default: 20), boost_exact_match (bool, default: True)
   - Returns: List of retrieval results with scores

3. **semantic_search(query, top_k, similarity_threshold)**: Vector-based semantic search
   - Use when: Need conceptual understanding
   - Parameters: query (str), top_k (int, default: 20), similarity_threshold (float, default: 0.0)
   - Returns: List of retrieval results with scores

4. **hybrid_search(query, top_k, bm25_weight, semantic_weight)**: Combined BM25 + semantic
   - Use when: Need balanced exact + conceptual matching
   - Parameters: query (str), top_k (int, default: 20), bm25_weight (float, default: 0.5), semantic_weight (float, default: 0.5)
   - Returns: List of retrieval results with scores

5. **rrf_fusion(result_ids, rrf_k, top_k)**: Fuse multiple result sets
   - Use when: Have results from multiple searches to combine
   - Parameters: result_ids (list of str), rrf_k (int, default: 60), top_k (int, default: 20)
   - Returns: Fused and deduplicated results

## Execution Strategy

**STEP 1: Analyze Query Characteristics**
- Does it contain specific CPT codes? ‚Üí Consider range_routing first
- What's the primary intent? definition/compatibility/policy
- Which strategies are recommended? {strategies_str}

**STEP 2: Plan Tool Calls**

**For queries with CPT codes:**
1. Call range_routing(cpt_code) for each CPT code mentioned
2. Then call appropriate search methods (bm25/semantic/hybrid)
3. Finally call rrf_fusion to combine results

**For queries without CPT codes:**
1. Call appropriate search methods for each query candidate
2. Use different strategies based on query type:
   - original: hybrid (balanced)
   - expanded: semantic (rich terminology)
   - section_specific: bm25 (exact matching)
   - constraint_focused: semantic (conceptual)
3. Call rrf_fusion to combine results

**STEP 3: Execute Tool Calls**
- Call tools in logical order
- Use results from previous tools to inform next calls
- Track result_ids for fusion

**STEP 4: Fuse and Return**
- Call rrf_fusion with all collected result_ids
- This will be your final output

## Example Execution Patterns

**Example 1: Simple Definition (CPT code present)**
Question: "What is CPT 14301?"
‚Üí Call: range_routing(cpt_code=14301, limit=200)
‚Üí Call: semantic_search(query="What is CPT 14301?", top_k=15)
‚Üí Call: rrf_fusion(result_ids=["range_14301", "semantic_0"], top_k=20)

**Example 2: Modifier Compatibility (CPT code present)**
Question: "Is modifier 59 allowed with CPT 14301?"
‚Üí Call: range_routing(cpt_code=14301, limit=300)
‚Üí Call: bm25_search(query="modifier 59 CPT 14301", top_k=20)
‚Üí Call: semantic_search(query="modifier 59 compatibility with adjacent tissue transfer", top_k=20)
‚Üí Call: rrf_fusion(result_ids=["bm25_0", "semantic_0"], top_k=20)

**Example 3: PTP Question (Two CPT codes)**
Question: "Can CPT 14301 and 27700 be billed together?"
‚Üí Call: range_routing(cpt_code=14301, limit=300)
‚Üí Call: range_routing(cpt_code=27700, limit=300)
‚Üí Call: bm25_search(query="CPT 14301 27700 billed together", top_k=20)
‚Üí Call: semantic_search(query="adjacent tissue transfer and wound repair billing compatibility", top_k=20)
‚Üí Call: rrf_fusion(result_ids=["bm25_0", "semantic_0"], top_k=20)

**Example 4: Conceptual Question (No CPT codes)**
Question: "What are the guidelines for billing adjacent tissue transfers?"
‚Üí Call: semantic_search(query="guidelines for billing adjacent tissue transfers", top_k=20)
‚Üí Call: hybrid_search(query="adjacent tissue transfer coding rules", top_k=20, bm25_weight=0.4, semantic_weight=0.6)
‚Üí Call: rrf_fusion(result_ids=["semantic_0", "hybrid_0"], top_k=20)

## Your Task

Based on the question and query candidates above, **CALL THE APPROPRIATE TOOLS** to retrieve relevant information.

**Important Guidelines:**
1. Use range_routing FIRST if CPT codes are present
2. Call search tools with different query candidates to get diverse results
3. Use bm25 for exact matching, semantic for concepts, hybrid for balance
4. Always finish with rrf_fusion to combine results
5. Track result_ids carefully for fusion

Start by calling the first tool now!
"""


# System message for retrieval router
RETRIEVAL_ROUTER_SYSTEM_MESSAGE = "You are a Retrieval Execution Planner for a medical coding RAG system. Your role is to create detailed retrieval plans that optimize search effectiveness by configuring parameters, mapping queries to strategies, and orchestrating parallel execution."
