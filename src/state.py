"""
State definition for Agentic RAG system
Defines the state that flows through the LangGraph workflow
"""
from typing import TypedDict, List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field


class RetrievalResult(BaseModel):
    """Single retrieval result"""
    chunk_id: str
    score: float
    text: str
    metadata: Dict[str, Any] = Field(default_factory=dict)


class QueryCandidate(BaseModel):
    """Query candidate generated by Query Planner"""
    query: str
    query_type: Literal["original", "expanded", "synonym", "section_specific", "constraint_focused"]
    weight: float = 1.0


class EvidenceAssessment(BaseModel):
    """Evidence quality assessment"""
    is_sufficient: bool
    coverage_score: float  # 0-1
    specificity_score: float  # 0-1
    citation_count: int
    has_contradiction: bool
    reasoning: str
    missing_aspects: List[str] = Field(default_factory=list)


class StructuredAnswer(BaseModel):
    """Final structured answer with evidence"""
    answer: str
    rules: List[str] = Field(default_factory=list)
    allowed_modifiers: List[str] = Field(default_factory=list)
    constraints: List[str] = Field(default_factory=list)
    risks: List[str] = Field(default_factory=list)
    evidence_trace: List[Dict[str, Any]] = Field(default_factory=list)
    confidence: float = 0.0


class AgenticRAGState(TypedDict):
    """State that flows through the LangGraph workflow"""
    
    # ========== Input ==========
    question: str
    cpt_code: Optional[int]
    context: Optional[str]
    
    # ========== Orchestrator outputs (Global Strategy Decisions) ==========
    question_type: Optional[Literal["modifier", "PTP", "guideline", "definition", "comparison", "procedural", "general"]]
    question_keywords: List[str]  # Keywords extracted from query (includes CPT codes, modifiers, medical terms)
    question_complexity: Optional[Literal["simple", "medium", "complex"]]
    retrieval_strategies: List[Literal["range_routing", "bm25", "semantic", "hybrid"]]  # Ordered pipeline
    enable_retry: bool  # Whether retry is enabled
    max_retry_allowed: int  # Max retries allowed (0-3)
    require_structured_output: bool  # Whether structured extraction is needed
    orchestrator_reasoning: Optional[str]  # Orchestrator's reasoning
    
    # Legacy fields (for backward compatibility)
    retrieval_strategy: Optional[Literal["bm25", "semantic", "hybrid"]]  # Deprecated: use retrieval_strategies
    
    
    # ========== Query Planner outputs ==========
    query_candidates: List[QueryCandidate]
    
    # ========== Retrieval outputs ==========
    retrieved_chunks: List[RetrievalResult]
    retrieval_metadata: Dict[str, Any]
    
    # ========== Evidence Judge outputs ==========
    evidence_assessment: Optional[EvidenceAssessment]
    retry_count: int
    
    # ========== Query Refiner outputs (for retry loop) ==========
    refined_queries: List[str]
    
    # ========== Final outputs ==========
    structured_answer: Optional[StructuredAnswer]
    
    # ========== System metadata ==========
    messages: List[str]  # Log messages for debugging
    error: Optional[str]
