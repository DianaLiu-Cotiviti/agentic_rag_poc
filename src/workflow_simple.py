"""
Simple Agentic RAG Workflow - æ— Iterationç‰ˆæœ¬
==============================================

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„workflowï¼Œç”¨äºéªŒè¯åŸºæœ¬çš„agent pipelineï¼š
User Query â†’ Orchestrator â†’ Query Planner â†’ Retrieval Router â†’ Evidence Judge â†’ END

ä¸åŒ…å«:
- Query Refiner (retryé€»è¾‘)
- Structured Extraction (æœ€ç»ˆç­”æ¡ˆç”Ÿæˆ)

ç”¨äºæµ‹è¯•æ¯ä¸ªagentæ˜¯å¦æ­£ç¡®è¿æ¥å’Œå·¥ä½œã€‚
"""

from typing import Dict, Any
from langgraph.graph import StateGraph, END

from .state import AgenticRAGState
from .config import AgenticRAGConfig
from .memory import WorkflowMemory
from .agents_coordinator import AgenticRAGAgents
from .tools.retrieval_tools import RetrievalTools
from .tools.build_indexes import ensure_all_indexes


class SimpleAgenticRAGWorkflow:
    """
    ç®€åŒ–çš„Agentic RAG Workflow
    
    æµç¨‹:
    1. Orchestrator â†’ åˆ†æé—®é¢˜ï¼Œé€‰æ‹©retrieval mode
    2. Query Planner â†’ ç”Ÿæˆquery candidates (å¦‚æœæ˜¯planning mode)
    3. Retrieval Router â†’ æ‰§è¡Œæ£€ç´¢ï¼Œè¿”å›top 15 chunks
    4. Evidence Judge â†’ è¯„ä¼°è´¨é‡ï¼ˆæ–°çš„chunk formatting + LLMæ€»ç»“ï¼‰
    5. END â†’ è¿”å›ç»“æœ
    
    ä½¿ç”¨æ–¹æ³•:
        config = AgenticRAGConfig.from_env()
        workflow = SimpleAgenticRAGWorkflow(config)
        result = workflow.run("What is CPT code 14301?")
    """
    
    def __init__(self, config: AgenticRAGConfig = None, enable_memory: bool = True):
        """
        åˆå§‹åŒ–workflow
        
        Args:
            config: é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½
            enable_memory: æ˜¯å¦å¯ç”¨memoryä¿å­˜åŠŸèƒ½ï¼ˆé»˜è®¤Trueï¼‰
        """
        self.config = config or AgenticRAGConfig.from_env()
        
        # åœ¨åˆå§‹åŒ–agentsä¹‹å‰ï¼Œç¡®ä¿æ‰€æœ‰indexeså·²æ„å»º
        print("\nğŸ”§ Preprocessing: Ensuring all indexes are built...")
        ensure_all_indexes(
            chunks_path=self.config.chunks_path,
            range_index_path=self.config.range_index_path,
            bm25_index_path=self.config.bm25_index_path,
            chroma_dir=self.config.chroma_db_path,
            config=self.config  # Pass config for embedding client
        )
        
        self.agents = AgenticRAGAgents(self.config)
        self.tools = RetrievalTools(self.config)
        self.graph = self._build_graph()
        
        # Memoryç®¡ç†å™¨
        self.enable_memory = enable_memory
        if self.enable_memory:
            self.memory = WorkflowMemory(memory_dir=self.config.memory_dir)
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºLangGraph workflow"""
        
        # åˆ›å»ºgraph
        workflow = StateGraph(AgenticRAGState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("orchestrator", self._orchestrator_node)
        workflow.add_node("query_planner", self._query_planner_node)
        workflow.add_node("retrieval", self._retrieval_node)
        workflow.add_node("evidence_judge", self._evidence_judge_node)
        
        # è®¾ç½®å…¥å£
        workflow.set_entry_point("orchestrator")
        
        # æ·»åŠ è¾¹ï¼ˆç®€å•çš„çº¿æ€§æµç¨‹ï¼‰
        workflow.add_edge("orchestrator", "query_planner")
        workflow.add_edge("query_planner", "retrieval")
        workflow.add_edge("retrieval", "evidence_judge")
        workflow.add_edge("evidence_judge", END)
        
        return workflow.compile()
    
    # ========== Node Functions ==========
    
    def _orchestrator_node(self, state: AgenticRAGState) -> AgenticRAGState:
        """
        OrchestratorèŠ‚ç‚¹
        
        èŒè´£ï¼š
        1. åˆ†æé—®é¢˜ç±»å‹ (cpt_code_lookup, billing_compatibility, etc.)
        2. é€‰æ‹©retrieval mode (direct, planning, tool_calling)
        3. è®¾ç½®max_retryï¼ˆè¿™é‡Œä¸ä½¿ç”¨ï¼Œä½†ä»è®¾ç½®ï¼‰
        """
        print("\n" + "="*80)
        print("ğŸ¯ Step 1: Orchestrator - Analyzing question...")
        print("="*80)
        
        result = self.agents.orchestrator_node(state)
        
        print(f"Question Type: {result.get('question_type')}")
        print(f"Complexity: {result.get('question_complexity')}")
        print(f"Strategy Hints: {result.get('retrieval_strategies')}")
        print(f"Reasoning: {result.get('orchestrator_reasoning', 'N/A')[:200]}...")
        
        state.update(result)
        return state
    
    def _query_planner_node(self, state: AgenticRAGState) -> AgenticRAGState:
        """
        Query PlannerèŠ‚ç‚¹
        
        èŒè´£ï¼š
        1. ç”Ÿæˆquery candidates (å¦‚æœæ˜¯planningæˆ–tool_calling mode)
        2. Direct modeä¼šè·³è¿‡è¿™ä¸€æ­¥ï¼ˆæˆ–ç”Ÿæˆminimal queriesï¼‰
        3. ä¿å­˜query candidatesåˆ°output/queries
        """
        print("\n" + "="*80)
        print("ğŸ“‹ Step 2: Query Planner - Generating query candidates...")
        print("="*80)
        
        result = self.agents.query_planner_node(state)
        
        query_candidates = result.get('query_candidates', [])
        print(f"Generated {len(query_candidates)} query candidates:")
        for i, qc in enumerate(query_candidates, 1):
            # qc is a QueryCandidate object
            query_text = qc.query if hasattr(qc, 'query') else str(qc)
            print(f"  {i}. {query_text}")
        
        # Save query candidates to output/queries
        if query_candidates:
            from .utils.save_workflow_outputs import save_query_candidates
            saved_path = save_query_candidates(
                query_candidates=query_candidates,
                question=state.get('question', ''),
                output_dir=self.config.query_output_dir,
                metadata={
                    'question_type': state.get('question_type'),
                    'question_complexity': state.get('question_complexity'),
                    'retrieval_strategies': state.get('retrieval_strategies'),
                    'mode': self.config.retrieval_mode
                }
            )
            print(f"ğŸ’¾ Query candidates saved to: {saved_path}")
        
        state.update(result)
        return state
    
    def _retrieval_node(self, state: AgenticRAGState) -> AgenticRAGState:
        """
        Retrieval RouterèŠ‚ç‚¹
        
        èŒè´£ï¼š
        1. æ ¹æ®modeæ‰§è¡Œå¯¹åº”çš„retrievalç­–ç•¥
        2. è¿”å›top 15-20 chunksï¼ˆå·²èåˆï¼‰
        """
        print("\n" + "="*80)
        print("ğŸ” Step 3: Retrieval Router - Executing retrieval...")
        print("="*80)
        
        # Mode comes from config, not from state
        mode = self.config.retrieval_mode
        print(f"Mode: {mode}")
        
        result = self.agents.retrieval_router_node(state, self.tools)
        
        chunks = result.get('retrieved_chunks', [])
        metadata = result.get('retrieval_metadata', {})
        
        # Show detailed execution based on mode
        execution_log = metadata.get('execution_log', [])
        if execution_log:
            # Tool calling mode - show iteration details
            print(f"\nğŸ“Š Tool Calling Execution Summary:")
            print(f"   Total iterations: {metadata.get('total_iterations', 0)}")
            print(f"   Total tool calls: {metadata.get('total_tool_calls', 0)}")
            
            print(f"\n  Detailed execution log:")
            for log in execution_log:
                print(f"    Iter {log['iteration']}: {log['tool_name']}(", end="")
                args_str = ", ".join(f"{k}={v}" for k, v in list(log['arguments'].items())[:2])
                print(f"{args_str}...) â†’ {log['chunks_returned']} chunks")
        else:
            # Planning or direct mode
            per_query_stats = metadata.get('per_query_stats', [])
            if per_query_stats:
                print(f"\nPer-query execution details:")
                for stats in per_query_stats:
                    print(f"\n  Query #{stats['query_index']}: {stats['strategy']}")
                    print(f"    Text: {stats['query_text']}")
                    print(f"    Weight: {stats['weight']:.2f}")
                    print(f"    Tools called: {', '.join(stats['tools_called'])}")
                    print(f"    Chunks retrieved: {stats['chunks_retrieved']}")
            else:
                # Direct mode - just show strategies
                strategies_used = metadata.get('strategies_used', [])
                if strategies_used:
                    print(f"\nStrategies executed:")
                    for strategy in strategies_used:
                        print(f"  â€¢ {strategy}")
        
        print(f"\nFinal results:")
        print(f"  Retrieved chunks: {len(chunks)}")
        if chunks:
            print(f"  Top chunk score: {chunks[0].score:.4f}")
            print(f"  Lowest chunk score: {chunks[-1].score:.4f}")
        
        state.update(result)
        return state
    
    def _evidence_judge_node(self, state: AgenticRAGState) -> AgenticRAGState:
        """
        Evidence JudgeèŠ‚ç‚¹
        
        èŒè´£ï¼š
        1. ä½¿ç”¨æ–°çš„ä¸‰å±‚chunk formattingç­–ç•¥
        2. LLMæ‰¹é‡æ€»ç»“æˆªæ–­éƒ¨åˆ†
        3. è¯„ä¼°coverage, specificity
        4. è¿”å›is_sufficientåˆ¤æ–­
        """
        print("\n" + "="*80)
        print("âš–ï¸  Step 4: Evidence Judge - Assessing evidence quality...")
        print("="*80)
        
        result = self.agents.evidence_judge_node(state)
        
        assessment = result.get('evidence_assessment', {})
        print(f"Is Sufficient: {assessment.get('is_sufficient')}")
        print(f"Coverage Score: {assessment.get('coverage_score', 0):.2f}")
        print(f"Specificity Score: {assessment.get('specificity_score', 0):.2f}")

        print(f"Has Contradiction: {assessment.get('has_contradiction')}")
        if assessment.get('missing_aspects'):
            print(f"Missing Aspects: {assessment.get('missing_aspects')}")
        print(f"\nReasoning:\n{assessment.get('reasoning', 'N/A')[:300]}...")
        
        state.update(result)
        return state
    
    # ========== Public Interface ==========
    
    def run(self, question: str, cpt_code: int = None, context: str = None) -> Dict[str, Any]:
        """
        è¿è¡Œç®€åŒ–çš„workflow
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            cpt_code: å¯é€‰çš„CPT codeï¼ˆç”¨äºrange filteringï¼‰
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡
            
        Returns:
            Dict: åŒ…å«å®Œæ•´çš„stateä¿¡æ¯
        """
        print("\n" + "ğŸš€" + "="*78 + "ğŸš€")
        print("Starting Simple Agentic RAG Workflow (No Iteration)")
        print("ğŸš€" + "="*78 + "ğŸš€")
        print(f"\nQuestion: {question}")
        if cpt_code:
            print(f"CPT Code: {cpt_code}")
        
        # åˆå§‹åŒ–state
        initial_state = AgenticRAGState(
            question=question,
            cpt_code=cpt_code,
            context=context,
        )
        
        # è¿è¡Œgraph
        final_state = self.graph.invoke(initial_state)
        
        print("\n" + "âœ…" + "="*78 + "âœ…")
        print("Workflow completed successfully!")
        print("âœ…" + "="*78 + "âœ…")
        
        # ä¿å­˜åˆ°memory
        if self.enable_memory:
            try:
                saved_path = self.memory.save_execution(
                    question=question,
                    final_state=final_state,
                    workflow_type="simple",
                    mode=self.config.retrieval_mode,
                    success=True
                )
                print(f"\nğŸ’¾ Workflow result saved to: {saved_path}")
            except Exception as e:
                print(f"\nâš ï¸  Failed to save memory: {e}")
        
        return final_state
    
    def visualize(self, output_path: str = "workflow_simple.png"):
        """
        å¯è§†åŒ–workflow graph
        
        Args:
            output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„
        """
        try:
            from IPython.display import Image, display
            display(Image(self.graph.get_graph().draw_mermaid_png()))
        except:
            print("Visualization requires IPython. Saving to file instead...")
            # ä¿å­˜åˆ°æ–‡ä»¶
            graph_image = self.graph.get_graph().draw_mermaid_png()
            with open(output_path, "wb") as f:
                f.write(graph_image)
            print(f"Graph saved to {output_path}")
